{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LJ1HTRWrdNfh",
        "outputId": "fbc020a2-e216-42f3-caa3-57e5d78da9d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating synthetic data...\n",
            "  historical matrix shape: (2000, 200)\n",
            "  current matrix shape:    (200, 200)\n",
            "  (synthetic true rank used to generate data: 8)\n",
            "\n",
            "Starting cross-validated rank selection on historical data...\n",
            "  fold 1/3 done\n",
            "  fold 2/3 done\n",
            "  fold 3/3 done\n",
            "\n",
            "CV mean AUC by rank (sorted):\n",
            "  rank  1: mean AUC = 0.7012\n",
            "  rank  2: mean AUC = 0.7763\n",
            "  rank  3: mean AUC = 0.8299\n",
            "  rank  4: mean AUC = 0.8665\n",
            "  rank  5: mean AUC = 0.8902\n",
            "  rank  6: mean AUC = 0.9045\n",
            "  rank  7: mean AUC = 0.9145\n",
            "  rank  8: mean AUC = 0.9185\n",
            "  rank  9: mean AUC = 0.9165\n",
            "  rank 10: mean AUC = 0.9146\n",
            "  rank 11: mean AUC = 0.9132\n",
            "  rank 12: mean AUC = 0.9114\n",
            "  rank 13: mean AUC = 0.9094\n",
            "  rank 14: mean AUC = 0.9081\n",
            "  rank 15: mean AUC = 0.9064\n",
            "  rank 16: mean AUC = 0.9049\n",
            "  rank 17: mean AUC = 0.9034\n",
            "  rank 18: mean AUC = 0.9023\n",
            "  rank 19: mean AUC = 0.9002\n",
            "  rank 20: mean AUC = 0.8994\n",
            "\n",
            "Selected best rank = 8\n",
            "\n",
            "Fitting TruncatedSVD on full historical matrix with best rank...\n",
            "  done.\n",
            "\n",
            "Masking 40% of current-order entries and predicting masked entries...\n",
            "\n",
            "Evaluation on masked current-order entries:\n",
            "  auc: 0.9173151087888377\n",
            "  ap: 0.9181912484717559\n",
            "  accuracy: 0.59631480324797\n",
            "  precision: 0.5539782563534381\n",
            "  recall: 0.9972575417601596\n",
            "  f1: 0.7122824199795219\n",
            "  n_eval: 16010\n",
            "\n",
            "Sample masked-entry predictions (first rows):\n",
            " row  part  true  pred_prob  pred_label_0.5\n",
            "  82     6     1   0.598036               1\n",
            "  82     7     1   0.724488               1\n",
            "  82    10     0   0.410979               0\n",
            "  82    19     0   0.571006               1\n",
            "  82    21     1   0.639067               1\n",
            "  82    22     0   0.612605               1\n",
            "  39     0     0   0.599780               1\n",
            "  39     1     1   0.646097               1\n",
            "  39     3     1   0.800210               1\n",
            "  39     4     0   0.541782               1\n",
            "  39     5     0   0.573268               1\n",
            "  39     8     1   0.759846               1\n",
            " 175     1     0   0.567595               1\n",
            " 175     3     1   0.587412               1\n",
            " 175     5     1   0.686028               1\n",
            " 175    11     0   0.561001               1\n",
            " 175    14     0   0.620624               1\n",
            " 175    16     0   0.591838               1\n",
            "  88     0     0   0.496124               0\n",
            "  88     2     0   0.506632               1\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "svd_order_recommender.py\n",
        "\n",
        "Full, runnable script that:\n",
        "- Generates synthetic historical and current \"orders x parts\" binary incidence matrices\n",
        "  from an underlying low-rank latent model.\n",
        "- Performs entry-wise cross-validated rank selection for Truncated SVD on historical data.\n",
        "- Fits final Truncated SVD to the full historical matrix using the selected rank.\n",
        "- Masks 40% of entries in the current (in-progress) orders, projects each partial row into the\n",
        "  learned item-space (least-squares), reconstructs scores for the masked entries, and evaluates\n",
        "  predictions (AUC, AP, accuracy, precision, recall, F1).\n",
        "- Prints summary results and a small sample of predicted vs true masked entries.\n",
        "\n",
        "Usage:\n",
        "    python svd_order_recommender.py\n",
        "\n",
        "Dependencies:\n",
        "    numpy, scipy, pandas, scikit-learn\n",
        "\n",
        "Adjust parameters at the top of the file (n_parts, n_hist, n_curr, candidate_ranks, etc).\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        ")\n",
        "from scipy.special import expit  # sigmoid\n",
        "import argparse\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def generate_synthetic_data(n_parts, n_hist, n_curr, true_rank, sigma_scale=2.0, seed=42):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    U_true = rng.normal(scale=1.0, size=(n_hist + n_curr, true_rank))\n",
        "    V_true = rng.normal(scale=1.0, size=(n_parts, true_rank))\n",
        "    sing_vals = np.linspace(sigma_scale, 0.5, true_rank)\n",
        "\n",
        "    scores_full = (U_true @ np.diag(sing_vals) @ V_true.T)\n",
        "    probs_full = expit(scores_full)\n",
        "    A_full = (rng.rand(*probs_full.shape) < probs_full).astype(int)\n",
        "\n",
        "    A_hist = A_full[:n_hist, :].copy()\n",
        "    A_curr = A_full[n_hist:, :].copy()\n",
        "    return A_hist, A_curr, (U_true, V_true, sing_vals)\n",
        "\n",
        "\n",
        "def fit_truncated_svd_and_reconstruct(A, n_components, random_state=42):\n",
        "    \"\"\"\n",
        "    Fit TruncatedSVD to A (array-like), return (svd, reconstruction_scores).\n",
        "    Note: TruncatedSVD.fit_transform returns U * S; reconstruction is (U*S) @ components_.\n",
        "    \"\"\"\n",
        "    svd = TruncatedSVD(n_components=n_components, random_state=random_state)\n",
        "    U_S = svd.fit_transform(A)\n",
        "    Vt = svd.components_\n",
        "    recon = U_S @ Vt\n",
        "    return svd, recon\n",
        "\n",
        "\n",
        "def evaluate_masked_predictions(scores, A_true, mask):\n",
        "    \"\"\"\n",
        "    Evaluate predictions on positions indicated by boolean mask (True -> evaluate).\n",
        "    scores: real-valued reconstruction scores (higher => more likely)\n",
        "    A_true: binary ground-truth matrix (0/1)\n",
        "    mask: boolean array, same shape, True where we evaluate (masked positions)\n",
        "    Returns dict of metrics, with 'n_eval'.\n",
        "    \"\"\"\n",
        "    if mask.sum() == 0:\n",
        "        return {\"n_eval\": 0}\n",
        "    # Map scores to probabilities with sigmoid (helps for AUC/AP)\n",
        "    y_true = A_true[mask].ravel()\n",
        "    y_scores = expit(scores[mask].ravel())\n",
        "    results = {}\n",
        "    # AUC may fail if only one label present\n",
        "    try:\n",
        "        results[\"auc\"] = roc_auc_score(y_true, y_scores)\n",
        "    except ValueError:\n",
        "        results[\"auc\"] = np.nan\n",
        "    results[\"ap\"] = (\n",
        "        average_precision_score(y_true, y_scores) if len(np.unique(y_true)) > 1 else np.nan\n",
        "    )\n",
        "    y_pred = (y_scores >= 0.5).astype(int)\n",
        "    results[\"accuracy\"] = accuracy_score(y_true, y_pred)\n",
        "    results[\"precision\"] = precision_score(y_true, y_pred, zero_division=0)\n",
        "    results[\"recall\"] = recall_score(y_true, y_pred, zero_division=0)\n",
        "    results[\"f1\"] = f1_score(y_true, y_pred, zero_division=0)\n",
        "    results[\"n_eval\"] = int(mask.sum())\n",
        "    return results\n",
        "\n",
        "\n",
        "def cross_validated_rank_selection(\n",
        "    A_hist,\n",
        "    candidate_ranks,\n",
        "    cv_folds=3,\n",
        "    val_fraction_hist=0.05,\n",
        "    random_state=42,\n",
        "):\n",
        "    \"\"\"\n",
        "    Entry-wise cross-validated rank selection.\n",
        "    For each fold:\n",
        "      - random subset of entries (val_fraction_hist) is masked (validation)\n",
        "      - TruncatedSVD is fit on the remainder (we center by global mean for stability)\n",
        "      - reconstruction is evaluated (AUC) on the masked entries\n",
        "    Returns: best_rank, rank_mean_auc (dict)\n",
        "    \"\"\"\n",
        "    rng = np.random.RandomState(random_state)\n",
        "    rank_scores = {r: [] for r in candidate_ranks}\n",
        "\n",
        "    for fold_idx in range(cv_folds):\n",
        "        mask_val = (rng.rand(*A_hist.shape) < val_fraction_hist)\n",
        "        A_train = A_hist.astype(float).copy()\n",
        "        global_mean = A_train.mean()\n",
        "        # center for better SVD performance\n",
        "        A_train_centered = A_train - global_mean\n",
        "        # hide validation positions by zeroing them (approximation)\n",
        "        A_train_centered[mask_val] = 0.0\n",
        "\n",
        "        for r in candidate_ranks:\n",
        "            svd_r = TruncatedSVD(n_components=r, random_state=random_state)\n",
        "            U_S = svd_r.fit_transform(A_train_centered)\n",
        "            Vt = svd_r.components_\n",
        "            recon_centered = U_S @ Vt\n",
        "            recon = recon_centered + global_mean\n",
        "            eval_r = evaluate_masked_predictions(recon, A_hist, mask_val)\n",
        "            rank_scores[r].append(eval_r.get(\"auc\", np.nan))\n",
        "        print(f\"  fold {fold_idx+1}/{cv_folds} done\")\n",
        "\n",
        "    rank_mean_auc = {r: np.nanmean(rank_scores[r]) for r in candidate_ranks}\n",
        "    # Choose best rank as argmax mean AUC (break ties by lower rank)\n",
        "    best_rank = max(candidate_ranks, key=lambda k: (np.nan_to_num(rank_mean_auc[k], -1e9), -k))\n",
        "    return best_rank, rank_mean_auc\n",
        "\n",
        "\n",
        "def project_new_rows_least_squares(Vt, A_row_observed, observed_mask_row, global_mean=0.0, reg=1e-3):\n",
        "    \"\"\"\n",
        "    Project a single new (partial) row into the learned latent space.\n",
        "    - Vt: (n_components, n_parts)\n",
        "    - A_row_observed: 1D array (n_parts,) with observed binary values\n",
        "    - observed_mask_row: boolean mask of observed positions (True for observed)\n",
        "    Returns:\n",
        "      - z: latent vector (n_components,)\n",
        "      - reconstructed_scores: real-valued scores for all parts (z @ Vt + global_mean)\n",
        "    \"\"\"\n",
        "    n_components = Vt.shape[0]\n",
        "    V = Vt.T  # (n_parts, n_components)\n",
        "    obs_idx = np.where(observed_mask_row)[0]\n",
        "    if len(obs_idx) == 0:\n",
        "        z = np.zeros(n_components)\n",
        "    else:\n",
        "        V_known = V[obs_idx, :]  # (n_obs, n_components)\n",
        "        y_known = A_row_observed[obs_idx].astype(float) - global_mean  # center observed targets\n",
        "        # regularized normal equations (ridge)\n",
        "        A_mat = V_known.T @ V_known + reg * np.eye(n_components)\n",
        "        b_vec = V_known.T @ y_known\n",
        "        try:\n",
        "            z = np.linalg.solve(A_mat, b_vec)\n",
        "        except np.linalg.LinAlgError:\n",
        "            z, *_ = np.linalg.lstsq(V_known, y_known, rcond=None)\n",
        "    row_scores_centered = z @ Vt\n",
        "    return z, row_scores_centered + global_mean\n",
        "\n",
        "\n",
        "def main(\n",
        "    n_parts=200,\n",
        "    n_hist=2000,\n",
        "    n_curr=200,\n",
        "    true_rank=8,\n",
        "    cv_folds=3,\n",
        "    candidate_ranks=None,\n",
        "    mask_fraction_curr=0.40,\n",
        "    val_fraction_hist=0.05,\n",
        "    random_seed=42,\n",
        "):\n",
        "    if candidate_ranks is None:\n",
        "        candidate_ranks = list(range(1, 21))\n",
        "\n",
        "    print(\"Generating synthetic data...\")\n",
        "    A_hist, A_curr, _ = generate_synthetic_data(\n",
        "        n_parts=n_parts,\n",
        "        n_hist=n_hist,\n",
        "        n_curr=n_curr,\n",
        "        true_rank=true_rank,\n",
        "        seed=random_seed,\n",
        "    )\n",
        "    print(f\"  historical matrix shape: {A_hist.shape}\")\n",
        "    print(f\"  current matrix shape:    {A_curr.shape}\")\n",
        "    print(f\"  (synthetic true rank used to generate data: {true_rank})\\n\")\n",
        "\n",
        "    # CV rank selection\n",
        "    print(\"Starting cross-validated rank selection on historical data...\")\n",
        "    best_rank, rank_mean_auc = cross_validated_rank_selection(\n",
        "        A_hist,\n",
        "        candidate_ranks=candidate_ranks,\n",
        "        cv_folds=cv_folds,\n",
        "        val_fraction_hist=val_fraction_hist,\n",
        "        random_state=random_seed,\n",
        "    )\n",
        "    print(\"\\nCV mean AUC by rank (sorted):\")\n",
        "    for r in sorted(rank_mean_auc.keys()):\n",
        "        print(f\"  rank {r:2d}: mean AUC = {rank_mean_auc[r]:.4f}\")\n",
        "    print(f\"\\nSelected best rank = {best_rank}\\n\")\n",
        "\n",
        "    # Fit final SVD on full historical matrix (centered)\n",
        "    print(\"Fitting TruncatedSVD on full historical matrix with best rank...\")\n",
        "    global_mean = A_hist.mean()\n",
        "    svd_final = TruncatedSVD(n_components=best_rank, random_state=random_seed)\n",
        "    U_S_full = svd_final.fit_transform(A_hist - global_mean)\n",
        "    Vt_final = svd_final.components_\n",
        "    recon_hist_full = U_S_full @ Vt_final + global_mean\n",
        "    print(\"  done.\\n\")\n",
        "\n",
        "    # Inference pipeline: mask fraction of current orders and predict masked entries\n",
        "    print(f\"Masking {mask_fraction_curr*100:.0f}% of current-order entries and predicting masked entries...\")\n",
        "    rng = np.random.RandomState(random_seed)\n",
        "    mask_curr = (rng.rand(*A_curr.shape) < mask_fraction_curr)  # True -> masked/evaluate\n",
        "    observed_mask_curr = ~mask_curr\n",
        "    scores_curr_pred = np.zeros_like(A_curr, dtype=float)\n",
        "\n",
        "    for i in range(A_curr.shape[0]):\n",
        "        z, row_scores = project_new_rows_least_squares(\n",
        "            Vt_final, A_curr[i, :], observed_mask_curr[i], global_mean=global_mean, reg=1e-3\n",
        "        )\n",
        "        scores_curr_pred[i, :] = row_scores\n",
        "\n",
        "    eval_results = evaluate_masked_predictions(scores_curr_pred, A_curr, mask_curr)\n",
        "    print(\"\\nEvaluation on masked current-order entries:\")\n",
        "    for k, v in eval_results.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "\n",
        "    # Show a small sample of masked predictions for inspection\n",
        "    sample_rows = rng.choice(A_curr.shape[0], size=min(10, A_curr.shape[0]), replace=False)\n",
        "    rows_sample = []\n",
        "    for i in sample_rows:\n",
        "        masked_idxs = np.where(mask_curr[i])[0]\n",
        "        if len(masked_idxs) == 0:\n",
        "            continue\n",
        "        # show up to 6 masked items for the row\n",
        "        for j in masked_idxs[:6]:\n",
        "            prob = float(expit(scores_curr_pred[i, j]))\n",
        "            rows_sample.append(\n",
        "                {\n",
        "                    \"row\": int(i),\n",
        "                    \"part\": int(j),\n",
        "                    \"true\": int(A_curr[i, j]),\n",
        "                    \"pred_prob\": prob,\n",
        "                    \"pred_label_0.5\": int(prob >= 0.5),\n",
        "                }\n",
        "            )\n",
        "    sample_df = pd.DataFrame(rows_sample)\n",
        "    if not sample_df.empty:\n",
        "        print(\"\\nSample masked-entry predictions (first rows):\")\n",
        "        print(sample_df.head(20).to_string(index=False))\n",
        "    else:\n",
        "        print(\"\\nNo masked entries found in sampled rows (try increasing mask_fraction_curr).\")\n",
        "\n",
        "    # Return objects for further programmatic use (if needed)\n",
        "    return {\n",
        "        \"A_hist\": A_hist,\n",
        "        \"A_curr\": A_curr,\n",
        "        \"svd_final\": svd_final,\n",
        "        \"Vt_final\": Vt_final,\n",
        "        \"recon_hist_full\": recon_hist_full,\n",
        "        \"scores_curr_pred\": scores_curr_pred,\n",
        "        \"mask_curr\": mask_curr,\n",
        "        \"eval_results\": eval_results,\n",
        "        \"sample_predictions\": sample_df,\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = main()\n"
      ]
    }
  ]
}