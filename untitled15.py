# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FCWLssfCJKrEV72ZWEzCdm4ui9PNWZ71
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.data import HeteroData
from torch_geometric.nn import HeteroConv, SAGEConv
from torch_geometric.utils import negative_sampling
from sklearn.metrics import roc_auc_score, average_precision_score
from sklearn.decomposition import TruncatedSVD
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict

# ----------------------------
# 0. Synthetic heterogeneous graph
# ----------------------------
num_orders = 50
num_products = 20
num_parts = 30

data = HeteroData()
data['order'].x = torch.randn(num_orders, 16)
data['product'].x = torch.randn(num_products, 16)
data['part'].x = torch.randn(num_parts, 16)

# edges
data['order','buys','product'].edge_index = torch.stack([
    torch.randint(0, num_orders, (200,)),
    torch.randint(0, num_products, (200,))
], dim=0)

data['product','contains','part'].edge_index = torch.stack([
    torch.randint(0, num_products, (300,)),
    torch.randint(0, num_parts, (300,))
], dim=0)

edge_index = torch.stack([
    torch.randint(0, num_orders, (150,)),
    torch.randint(0, num_parts, (150,))
], dim=0)

# Train/test split
perm = torch.randperm(edge_index.size(1))
train_idx = perm[:int(0.8*edge_index.size(1))]
test_idx = perm[int(0.8*edge_index.size(1)):]
train_edges = edge_index[:, train_idx]
test_edges = edge_index[:, test_idx]

data['order','needs','part'].edge_index = train_edges
data['part','rev_needs','order'].edge_index = train_edges.flip(0)

# ----------------------------
# 1. Frequency baseline
# ----------------------------
def build_freq_model(train_edges):
    freq = defaultdict(int)
    order_counts = defaultdict(int)
    for o, p in zip(train_edges[0], train_edges[1]):
        freq[(o.item(), p.item())] += 1
        order_counts[o.item()] += 1
    return freq, order_counts

def predict_freq(freq, order_counts, order_ids, part_ids):
    scores = []
    for o, p in zip(order_ids, part_ids):
        scores.append(freq.get((o.item(), p.item()), 0) / (order_counts.get(o.item(), 1)))
    return torch.tensor(scores, dtype=torch.float)

# ----------------------------
# 2. Matrix Factorization (SVD)
# ----------------------------
def build_svd_model(train_edges, num_orders, num_parts, k=16):
    mat = np.zeros((num_orders, num_parts))
    for o, p in zip(train_edges[0], train_edges[1]):
        mat[o, p] = 1
    svd = TruncatedSVD(n_components=k)
    U = svd.fit_transform(mat)
    V = svd.components_.T
    return torch.tensor(U, dtype=torch.float), torch.tensor(V, dtype=torch.float)

def predict_svd(U, V, order_ids, part_ids):
    scores = []
    for o, p in zip(order_ids, part_ids):
        scores.append((U[o] * V[p]).sum().item())
    return torch.tensor(scores, dtype=torch.float)

# ----------------------------
# 3. GNN Encoder + Decoder
# ----------------------------
class HeteroGNN(nn.Module):
    def __init__(self, hidden_channels):
        super().__init__()
        self.conv1 = HeteroConv({
            ('order','buys','product'): SAGEConv((-1,-1), hidden_channels),
            ('product','contains','part'): SAGEConv((-1,-1), hidden_channels),
            ('part','rev_needs','order'): SAGEConv((-1,-1), hidden_channels),
        }, aggr='mean')

    def forward(self, x_dict, edge_index_dict):
        x_dict = self.conv1(x_dict, edge_index_dict)
        return {k: F.relu(v) for k,v in x_dict.items()}

class DotProductDecoder(nn.Module):
    def forward(self, z_dict, edge_index):
        src, dst = edge_index
        return (z_dict['order'][src] * z_dict['part'][dst]).sum(dim=-1)

# ----------------------------
# 4. Graph heuristics (manual)
# ----------------------------
def build_neighbor_dict(edges):
    neighbors = defaultdict(set)
    for u, v in zip(edges[0], edges[1]):
        neighbors[u.item()].add(v.item())
        neighbors[v.item()].add(u.item())
    return neighbors

def compute_jaccard(edges, edge_label_index):
    neighbors = build_neighbor_dict(edges)
    scores = []
    for u, v in zip(edge_label_index[0], edge_label_index[1]):
        n_u = neighbors[u.item()]
        n_v = neighbors[v.item()]
        intersection = len(n_u & n_v)
        union = len(n_u | n_v)
        scores.append(intersection / union if union > 0 else 0.0)
    return torch.tensor(scores, dtype=torch.float)

def compute_adamic_adar(edges, edge_label_index):
    neighbors = build_neighbor_dict(edges)
    scores = []
    for u, v in zip(edge_label_index[0], edge_label_index[1]):
        common = neighbors[u.item()] & neighbors[v.item()]
        score = sum(1.0 / torch.log(torch.tensor(len(neighbors[z]), dtype=torch.float) + 1e-8) for z in common)
        scores.append(score)  # <-- remove .item()
    return torch.tensor(scores, dtype=torch.float)

# ----------------------------
# Evaluation utility
# ----------------------------
def get_link_labels(pos_edge_index, neg_edge_index):
    pos_y = torch.ones(pos_edge_index.size(1))
    neg_y = torch.zeros(neg_edge_index.size(1))
    return torch.cat([pos_y, neg_y], dim=0)

def evaluate(pred, labels):
    pred = pred.detach().cpu().numpy()
    labels = labels.detach().cpu().numpy()
    return roc_auc_score(labels, pred), average_precision_score(labels, pred)

# ----------------------------
# Run evaluation
# ----------------------------
results = {}

# Negative samples for test
neg_test = negative_sampling(train_edges, num_nodes=(num_orders, num_parts),
                             num_neg_samples=test_edges.size(1))
edge_label_index = torch.cat([test_edges, neg_test], dim=1)
edge_label = get_link_labels(test_edges, neg_test)

# 1. Frequency
freq, order_counts = build_freq_model(train_edges)
pred_freq = predict_freq(freq, order_counts, edge_label_index[0], edge_label_index[1])
results['Frequency'] = evaluate(pred_freq, edge_label)

# 2. Matrix Factorization
U, V = build_svd_model(train_edges, num_orders, num_parts)
pred_svd = predict_svd(U, V, edge_label_index[0], edge_label_index[1])
results['MatrixFactorization'] = evaluate(pred_svd, edge_label)

# 3. GNN
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = HeteroGNN(hidden_channels=32).to(device)
decoder = DotProductDecoder().to(device)
data = data.to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

for epoch in range(30):
    model.train()
    optimizer.zero_grad()
    z_dict = model(data.x_dict, data.edge_index_dict)
    pos_edge_index = train_edges
    neg_edge_index = negative_sampling(
        edge_index=pos_edge_index,
        num_nodes=(num_orders,num_parts),
        num_neg_samples=pos_edge_index.size(1)
    )
    edge_label_index_train = torch.cat([pos_edge_index, neg_edge_index], dim=1).to(device)
    edge_label_train = get_link_labels(pos_edge_index, neg_edge_index).to(device)
    out = decoder(z_dict, edge_label_index_train)
    loss = F.binary_cross_entropy_with_logits(out, edge_label_train)
    loss.backward()
    optimizer.step()

model.eval()
with torch.no_grad():
    z_dict = model(data.x_dict, data.edge_index_dict)
    pred_gnn = decoder(z_dict, edge_label_index.to(device)).sigmoid().cpu()
results['GNN'] = evaluate(pred_gnn, edge_label)

# 4. Jaccard
pred_jacc = compute_jaccard(train_edges, edge_label_index)
results['Jaccard'] = evaluate(pred_jacc, edge_label)

# 5. Adamic-Adar
pred_aa = compute_adamic_adar(train_edges, edge_label_index)
results['AdamicAdar'] = evaluate(pred_aa, edge_label)

# ----------------------------
# Print Results + Plot
# ----------------------------
for method, (auc, ap) in results.items():
    print(f"{method:20s} AUC={auc:.4f}, AP={ap:.4f}")

methods = list(results.keys())
aucs = [results[m][0] for m in methods]
aps = [results[m][1] for m in methods]

x = np.arange(len(methods))
width = 0.35

plt.figure(figsize=(12,5))

# AUC plot
plt.subplot(1,2,1)
plt.bar(x, aucs, width, color="skyblue")
plt.xticks(x, methods, rotation=20)
plt.ylabel("ROC-AUC")
plt.title("Model Comparison (AUC)")
plt.ylim(0, 1)

# AP plot
plt.subplot(1,2,2)
plt.bar(x, aps, width, color="lightgreen")
plt.xticks(x, methods, rotation=20)
plt.ylabel("Average Precision")
plt.title("Model Comparison (AP)")
plt.ylim(0, 1)

plt.tight_layout()
plt.show()